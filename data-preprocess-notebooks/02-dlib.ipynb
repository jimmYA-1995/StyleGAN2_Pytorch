{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face landmark detection with Dlib\n",
    "使用 Dlib 預測 68 facial landmarks，用來作為 FFHQ face alignment 的輸入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from random import sample\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27753"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANDMARK_PREDICTOR = Path('~/models/dlib/shape_predictor_68_face_landmarks.dat').expanduser()\n",
    "DATA_PATHS = list(Path('deepfashion_1024x1024/').glob('*.jpg'))\n",
    "len(DATA_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_to_bb(rect):\n",
    "\tx = rect.left()\n",
    "\ty = rect.top()\n",
    "\tw = rect.right() - x\n",
    "\th = rect.bottom() - y\n",
    "\treturn (x, y, w, h)\n",
    "\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "\tcoords = np.zeros((68, 2), dtype=dtype)\n",
    "\tfor i in range(0, 68):\n",
    "\t\tcoords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "        \n",
    "\t# return the list of (x, y)-coordinates\n",
    "\treturn coords\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(str(LANDMARK_PREDICTOR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "SHOW = False\n",
    "RETURN_SCORES = False\n",
    "num = 0\n",
    "\n",
    "def detect_face_and_landmarks(p, return_scores=False):\n",
    "    boxes, shapes = [], []\n",
    "    img = cv2.cvtColor(cv2.imread(str(p)), cv2.COLOR_BGR2RGB)\n",
    "    # rects = detector(img, 1)\n",
    "    rects, scores, idx = detector.run(img, 1)\n",
    "    \n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(img, rect)\n",
    "        shapes.append(shape_to_np(shape))\n",
    "        boxes.append(rect_to_bb(rect))\n",
    "        \n",
    "    if return_scores:\n",
    "        return boxes, shapes, scores, idx\n",
    "    \n",
    "    return boxes, shapes\n",
    "        \n",
    "with ThreadPoolExecutor() as executor:\n",
    "    func = partial(detect_face_and_landmarks, return_scores=RETURN_SCORES)\n",
    "    results = executor.map(func, sample(DATA_PATHS, 100))\n",
    "    \n",
    "    for result in results:\n",
    "        if RETURN_SCORES:\n",
    "            boxes, shapes, scores, idx = result\n",
    "        else:\n",
    "            boxes, shapes = result\n",
    "        \n",
    "        for box, shape in zip(boxes, shapes):\n",
    "            x, y, w, h = box\n",
    "    \n",
    "            if SHOW:\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(img, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                for (x, y) in shape:\n",
    "                    cv2.circle(img, (x, y), 1, (0, 0, 255), -1)\n",
    "    if SHOW:\n",
    "        display(Image.fromarray(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to json file (FFHQ format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32796/32796 [5:17:07<00:00,  1.72it/s]  \n"
     ]
    }
   ],
   "source": [
    "outputs = {}\n",
    "num = 0\n",
    "for p in tqdm(DATA_PATHS):\n",
    "    num += 1\n",
    "    output = {'in_the_wild': {}}\n",
    "    output['in_the_wild']['file_path'] = str(p)\n",
    "    img = cv2.cvtColor(cv2.imread(str(p)), cv2.COLOR_BGR2RGB)\n",
    "    rects = detector(img, 1)\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(img, rect)\n",
    "        shape = shape_to_np(shape)\n",
    "        # convert dlib's rectangle to a OpenCV-style bounding box\n",
    "        # [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "        (x, y, w, h) = rect_to_bb(rect)\n",
    "        output['in_the_wild']['box'] = [x, y, w, h]\n",
    "        output['in_the_wild']['face_landmarks'] = shape.tolist()\n",
    "        #cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # show the face number\n",
    "        #cv2.putText(img, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
    "        #            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        #for (x, y) in shape:\n",
    "        #    cv2.circle(img, (x, y), 1, (0, 0, 255), -1)\n",
    "    outputs[str(num)] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(outputs, open('df_landmarks.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
