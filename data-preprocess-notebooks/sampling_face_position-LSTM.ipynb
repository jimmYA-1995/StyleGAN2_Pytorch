{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets\n",
    "* resampling on face bbox coords. & facial landmarks\n",
    "* Using same algorithm of alignment to get quad.\n",
    "* perform inverse transformation on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "from random import sample\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as io\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22204\n"
     ]
    }
   ],
   "source": [
    "!ls ~/data/DeepFashion/kp_heatmaps/keypoints/train | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22204\n"
     ]
    }
   ],
   "source": [
    "!ls ~/data/DeepFashion/AB_RGBA_quad/train | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KP_THRES = 0.05\n",
    "NUM_DIM = 5\n",
    "OUTPUT_SIZE = 256\n",
    "ENABLE_PADDING = True\n",
    "IMG_SIZE = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img: 22204, Keypoins: 22204, landmarks: 22204\n"
     ]
    }
   ],
   "source": [
    "TRAIN_IMG_PATHS = sorted(list(Path('~/data/DeepFashion/AB_RGBA_quad/train').expanduser().glob('*.png')))\n",
    "VAL_IMG_PATHS = sorted(list(Path('~/data/DeepFashion/AB_RGBA_quad/val').expanduser().glob('*.png')))\n",
    "KP_FILES = {p.stem: p for p in Path('~/data/DeepFashion/kp_heatmaps/keypoints/train/').expanduser().glob('*.pkl')}\n",
    "\n",
    "DLIB_OUTPUTS = json.load(open('./deepfashion_landmarks.json', 'r'))\n",
    "to_keep = [p.stem for p in TRAIN_IMG_PATHS]\n",
    "LANDMARKS = {Path(item['in_the_wild']['file_path']).stem: np.array(item['in_the_wild']['face_landmarks']) \n",
    "             for item in DLIB_OUTPUTS.values() if Path(item['in_the_wild']['file_path']).stem in to_keep}\n",
    "BOXES = {Path(item['in_the_wild']['file_path']).stem: np.array(item['in_the_wild']['box']) \n",
    "             for item in DLIB_OUTPUTS.values() if Path(item['in_the_wild']['file_path']).stem in to_keep}\n",
    "\n",
    "print(f\"img: {len(TRAIN_IMG_PATHS)}, Keypoins: {len(KP_FILES)}, landmarks: {len(LANDMARKS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(KP_FILES.keys())) == set([p.stem for p in TRAIN_IMG_PATHS]) and set([p.stem for p in TRAIN_IMG_PATHS]) == set(list(LANDMARKS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake Images from StyleGAN2-ada"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fake_img_paths = list(Path('/home/u3534611/data/stylgan2-ada-outputs/').glob('*.png'))\n",
    "print(\"total: \", len(fake_img_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_point(imgd, point, r=3, color=\"#ff0000\"):\n",
    "    point = point.astype(int)\n",
    "    imgd.ellipse([*(point - r), *(point + r)], fill=color)\n",
    "    \n",
    "def draw_quad(imgd, quad, color=\"#ff0000\"):\n",
    "    display_quad = np.where(quad < 0, 0, quad).astype(int)\n",
    "    print(display_quad)\n",
    "    for idx in reversed(range(display_quad.shape[0])):\n",
    "        imgd.line([*display_quad[idx], *display_quad[idx - 1]], fill=color)\n",
    "\n",
    "def gallery(imgs):\n",
    "    if isinstance(imgs, list):\n",
    "        imgs = np.array(imgs)\n",
    "    \n",
    "    b, h, w, c = imgs.shape\n",
    "    return imgs.transpose(1, 0, 2, 3).reshape(h, b*w, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quad_x1</th>\n",
       "      <th>quad_y1</th>\n",
       "      <th>quad_x2</th>\n",
       "      <th>quad_y2</th>\n",
       "      <th>quad_x3</th>\n",
       "      <th>quad_y3</th>\n",
       "      <th>quad_x4</th>\n",
       "      <th>quad_y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108.962333</td>\n",
       "      <td>3.588691</td>\n",
       "      <td>111.351191</td>\n",
       "      <td>40.762667</td>\n",
       "      <td>148.525167</td>\n",
       "      <td>38.373809</td>\n",
       "      <td>146.136309</td>\n",
       "      <td>1.199833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.786305</td>\n",
       "      <td>11.326411</td>\n",
       "      <td>103.901411</td>\n",
       "      <td>66.401195</td>\n",
       "      <td>158.976195</td>\n",
       "      <td>48.286089</td>\n",
       "      <td>140.861089</td>\n",
       "      <td>-6.788695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.038303</td>\n",
       "      <td>3.273537</td>\n",
       "      <td>74.023537</td>\n",
       "      <td>59.724197</td>\n",
       "      <td>130.474197</td>\n",
       "      <td>53.738963</td>\n",
       "      <td>124.488963</td>\n",
       "      <td>-2.711697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145.946139</td>\n",
       "      <td>4.740020</td>\n",
       "      <td>142.746270</td>\n",
       "      <td>44.022611</td>\n",
       "      <td>182.028861</td>\n",
       "      <td>47.222480</td>\n",
       "      <td>185.228730</td>\n",
       "      <td>7.939889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.246365</td>\n",
       "      <td>4.952893</td>\n",
       "      <td>115.934143</td>\n",
       "      <td>63.372385</td>\n",
       "      <td>174.353635</td>\n",
       "      <td>45.684607</td>\n",
       "      <td>156.665857</td>\n",
       "      <td>-12.734885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22199</th>\n",
       "      <td>89.810443</td>\n",
       "      <td>19.702250</td>\n",
       "      <td>101.308500</td>\n",
       "      <td>77.233307</td>\n",
       "      <td>158.839557</td>\n",
       "      <td>65.735250</td>\n",
       "      <td>147.341500</td>\n",
       "      <td>8.204193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22200</th>\n",
       "      <td>110.444918</td>\n",
       "      <td>5.699087</td>\n",
       "      <td>110.730337</td>\n",
       "      <td>43.211332</td>\n",
       "      <td>148.242582</td>\n",
       "      <td>42.925913</td>\n",
       "      <td>147.957163</td>\n",
       "      <td>5.413668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22201</th>\n",
       "      <td>97.184613</td>\n",
       "      <td>7.430013</td>\n",
       "      <td>98.973763</td>\n",
       "      <td>45.959137</td>\n",
       "      <td>137.502887</td>\n",
       "      <td>44.169987</td>\n",
       "      <td>135.713737</td>\n",
       "      <td>5.640863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22202</th>\n",
       "      <td>77.183857</td>\n",
       "      <td>-10.653180</td>\n",
       "      <td>83.021820</td>\n",
       "      <td>65.403643</td>\n",
       "      <td>159.078643</td>\n",
       "      <td>59.565680</td>\n",
       "      <td>153.240680</td>\n",
       "      <td>-16.491143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22203</th>\n",
       "      <td>107.103326</td>\n",
       "      <td>13.472738</td>\n",
       "      <td>105.178988</td>\n",
       "      <td>53.327924</td>\n",
       "      <td>145.034174</td>\n",
       "      <td>55.252262</td>\n",
       "      <td>146.958512</td>\n",
       "      <td>15.397076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22204 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          quad_x1    quad_y1     quad_x2    quad_y2     quad_x3    quad_y3  \\\n",
       "0      108.962333   3.588691  111.351191  40.762667  148.525167  38.373809   \n",
       "1       85.786305  11.326411  103.901411  66.401195  158.976195  48.286089   \n",
       "2       68.038303   3.273537   74.023537  59.724197  130.474197  53.738963   \n",
       "3      145.946139   4.740020  142.746270  44.022611  182.028861  47.222480   \n",
       "4       98.246365   4.952893  115.934143  63.372385  174.353635  45.684607   \n",
       "...           ...        ...         ...        ...         ...        ...   \n",
       "22199   89.810443  19.702250  101.308500  77.233307  158.839557  65.735250   \n",
       "22200  110.444918   5.699087  110.730337  43.211332  148.242582  42.925913   \n",
       "22201   97.184613   7.430013   98.973763  45.959137  137.502887  44.169987   \n",
       "22202   77.183857 -10.653180   83.021820  65.403643  159.078643  59.565680   \n",
       "22203  107.103326  13.472738  105.178988  53.327924  145.034174  55.252262   \n",
       "\n",
       "          quad_x4    quad_y4  \n",
       "0      146.136309   1.199833  \n",
       "1      140.861089  -6.788695  \n",
       "2      124.488963  -2.711697  \n",
       "3      185.228730   7.939889  \n",
       "4      156.665857 -12.734885  \n",
       "...           ...        ...  \n",
       "22199  147.341500   8.204193  \n",
       "22200  147.957163   5.413668  \n",
       "22201  135.713737   5.640863  \n",
       "22202  153.240680 -16.491143  \n",
       "22203  146.958512  15.397076  \n",
       "\n",
       "[22204 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_observations(paths, include_box=False):\n",
    "    observations = []\n",
    "    headers = ['box_x1', 'box_y1', 'box_x2', 'box_y2', 'crop_x1', 'crop_y1', 'crop_x2', 'crop_y2'] if include_box else []\n",
    "    headers += ['quad_x1', 'quad_y1', 'quad_x2', 'quad_y2', 'quad_x3', 'quad_y3', 'quad_x4', 'quad_y4']\n",
    "    for p in paths: #sample(TRAIN_IMG_PATHS, 5):\n",
    "        observation = []\n",
    "        if include_box:\n",
    "            x1, y1, w, h = BOXES[p.stem]\n",
    "            x2, y2 = x1 + w, y1 + h\n",
    "            observation = [x1/4, y1/4, x2/4, y2/4]\n",
    "\n",
    "        lm = np.array(LANDMARKS[p.stem])\n",
    "        lm_chin          = lm[0  : 17]  # left-right\n",
    "        lm_eyebrow_left  = lm[17 : 22]  # left-right\n",
    "        lm_eyebrow_right = lm[22 : 27]  # left-right\n",
    "        lm_nose          = lm[27 : 31]  # top-down\n",
    "        lm_nostrils      = lm[31 : 36]  # top-down\n",
    "        lm_eye_left      = lm[36 : 42]  # left-clockwise\n",
    "        lm_eye_right     = lm[42 : 48]  # left-clockwise\n",
    "        lm_mouth_outer   = lm[48 : 60]  # left-clockwise\n",
    "        lm_mouth_inner   = lm[60 : 68]  # left-clockwise\n",
    "\n",
    "        # Calculate auxiliary vectors.\n",
    "        eye_left     = np.mean(lm_eye_left, axis=0)\n",
    "        eye_right    = np.mean(lm_eye_right, axis=0)\n",
    "        eye_avg      = (eye_left + eye_right) * 0.5\n",
    "        eye_to_eye   = eye_right - eye_left\n",
    "        mouth_left   = lm_mouth_outer[0]\n",
    "        mouth_right  = lm_mouth_outer[6]\n",
    "        mouth_avg    = (mouth_left + mouth_right) * 0.5\n",
    "        eye_to_mouth = mouth_avg - eye_avg\n",
    "\n",
    "        # Choose oriented crop rectangle.\n",
    "        x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]\n",
    "        x /= np.hypot(*x)\n",
    "        x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n",
    "        y = np.flipud(x) * [-1, 1]\n",
    "        c = eye_avg + eye_to_mouth * 0.1\n",
    "        quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\n",
    "        qsize = np.hypot(*x) * 2\n",
    "\n",
    "        # shrink = int(np.floor(qsize / OUTPUT_SIZE * 0.5))\n",
    "        # print(\"shrink: \", shrink)\n",
    "        # if shrink > 1:\n",
    "        #     rsize = (int(np.rint(float(img.size[0]) / shrink)), int(np.rint(float(img.size[1]) / shrink)))\n",
    "        #     img = img.resize(rsize, PIL.Image.ANTIALIAS)\n",
    "        #     quad /= shrink\n",
    "        #     qsize /= shrink\n",
    "\n",
    "        # Crop.\n",
    "        if include_box:\n",
    "            border = max(int(np.rint(qsize * 0.1)), 3)\n",
    "            crop = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
    "            crop = (max(crop[0] - border, 0) / 4., max(crop[1] - border, 0) / 4., min(crop[2] + border, IMG_SIZE[0]) / 4., min(crop[3] + border, IMG_SIZE[1]) / 4.)\n",
    "            observation.extend(crop)\n",
    "\n",
    "        # padding\n",
    "        # pad = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
    "        # pad = (max(-pad[0] + border, 0), max(-pad[1] + border, 0), max(pad[2] - img.size[0] + border, 0), max(pad[3] - img.size[1] + border, 0))\n",
    "        # print(\"pad: \", pad)\n",
    "        # if ENABLE_PADDING and max(pad) > border - 4:\n",
    "        #     pad = np.maximum(pad, int(np.rint(qsize * 0.3)))\n",
    "        #     img = np.pad(np.float32(img), ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\n",
    "        #     h, w, _ = img.shape\n",
    "        #     y, x, _ = np.ogrid[:h, :w, :1]\n",
    "        #     mask = np.maximum(1.0 - np.minimum(np.float32(x) / pad[0], np.float32(w-1-x) / pad[2]), 1.0 - np.minimum(np.float32(y) / pad[1], np.float32(h-1-y) / pad[3]))\n",
    "        #     blur = qsize * 0.02\n",
    "        #     img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) - img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\n",
    "        #     img += (np.median(img, axis=(0,1)) - img) * np.clip(mask, 0.0, 1.0)\n",
    "        #     img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img), 0, 255)), 'RGB')\n",
    "        #     quad += pad[:2]\n",
    "\n",
    "        observation.extend(quad.flatten() / 4)\n",
    "        observations.append(observation)\n",
    "\n",
    "    return pd.DataFrame(observations, columns=headers)\n",
    "\n",
    "observations = get_observations(TRAIN_IMG_PATHS)\n",
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22204, 8, 1])\n",
      "torch.Size([5, 8, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "rnn = torch.nn.LSTM(1, 1, 1)\n",
    "data = torch.from_numpy(observations.values[..., None]).float()\n",
    "print(data.shape)\n",
    "h0 = torch.randn(1, data.shape[1], 1)\n",
    "c0 = torch.randn(1, data.shape[1], 1)\n",
    "output, (hn, cn) = rnn(data[:5], (h0, c0))\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(rnn, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
