{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "# from torchsummary import summary\n",
    "from models import Generator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Generator(512, 0, 256, extra_channels=0, is_training=True)# .to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Discriminator(0, 256, extra_channels=0) #.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ema = Generator(512, 0, 256, extra_channels=0, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_numpy.pkl', 'rb') as f:\n",
    "    w = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lod\n",
    "dlatent_avg\n",
    "\n",
    "G_synthesis\n",
    "noise 0-12\n",
    "Const/const\n",
    "4x4 Conv ToRGB 5 4\n",
    "4x4 / Conv / weight mod_weight mod_bias noise_stength bias\n",
    "4x4 / ToRGB / weight mod_weight mod_bias bias\n",
    "8x8 Conv0_up Conv1 ToRGB 5 5 4\n",
    "16x16  Conv0_up Conv1 ToRGB 5 5 4\n",
    "32x32 Conv0_up Conv1 ToRGB 5 5 4\n",
    "64x64 Conv0_up Conv1 ToRGB 5 5 4\n",
    "128x128 Conv0_up Conv1 ToRGB 5 5 4\n",
    "256x256 Conv ToRGB 5 4\n",
    "\n",
    "G_mapping\n",
    "Dense0 weight bias\n",
    "Dense1 weight bias\n",
    "Dense2 weight bias\n",
    "Dense3 weight bias\n",
    "Dense4 weight bias\n",
    "Dense5 weight bias\n",
    "Dense6 weight bias\n",
    "Dense7 weight bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv2my_G = {\n",
    "'lod': '',\n",
    "'dlatent_avg': '',\n",
    "'G_synthesis/noise0': '',\n",
    "'G_synthesis/noise1': '',\n",
    "'G_synthesis/noise2': '',\n",
    "'G_synthesis/noise3': '',\n",
    "'G_synthesis/noise4': '',\n",
    "'G_synthesis/noise5': '',\n",
    "'G_synthesis/noise6': '',\n",
    "'G_synthesis/noise7': '',\n",
    "'G_synthesis/noise8': '',\n",
    "'G_synthesis/noise9': '',\n",
    "'G_synthesis/noise10': '',\n",
    "'G_synthesis/noise11': '',\n",
    "'G_synthesis/noise12': '',\n",
    "'G_synthesis/4x4/Const/const': 'synthesis_network.input',\n",
    "'G_synthesis/4x4/Conv/weight': 'synthesis_network.bottom_layer.conv.w',\n",
    "'G_synthesis/4x4/Conv/mod_weight': 'synthesis_network.bottom_layer.conv.dense.w',\n",
    "'G_synthesis/4x4/Conv/mod_bias': 'synthesis_network.bottom_layer.conv.dense.b',\n",
    "'G_synthesis/4x4/Conv/noise_strength': 'synthesis_network.bottom_layer.noise.noise_strength',\n",
    "'G_synthesis/4x4/Conv/bias': 'synthesis_network.bottom_layer.act.bias',\n",
    "'G_synthesis/4x4/ToRGB/weight': 'synthesis_network.trgbs.0.conv.w',\n",
    "'G_synthesis/4x4/ToRGB/mod_weight': 'synthesis_network.trgbs.0.conv.dense.w',\n",
    "'G_synthesis/4x4/ToRGB/mod_bias': 'synthesis_network.trgbs.0.conv.dense.b',\n",
    "'G_synthesis/4x4/ToRGB/bias': 'synthesis_network.trgbs.0.bias',\n",
    "'G_synthesis/8x8/Conv0_up/weight': 'synthesis_network.convs.0.conv.w',\n",
    "'G_synthesis/8x8/Conv0_up/mod_weight': 'synthesis_network.convs.0.conv.dense.w',\n",
    "'G_synthesis/8x8/Conv0_up/mod_bias': 'synthesis_network.convs.0.conv.dense.b',\n",
    "'G_synthesis/8x8/Conv0_up/noise_strength': 'synthesis_network.convs.0.noise.noise_strength',\n",
    "'G_synthesis/8x8/Conv0_up/bias': 'synthesis_network.convs.0.act.bias',\n",
    "'G_synthesis/8x8/Conv1/weight': 'synthesis_network.convs.1.conv.w',\n",
    "'G_synthesis/8x8/Conv1/mod_weight': 'synthesis_network.convs.1.conv.dense.w',\n",
    "'G_synthesis/8x8/Conv1/mod_bias': 'synthesis_network.convs.1.conv.dense.b',\n",
    "'G_synthesis/8x8/Conv1/noise_strength': 'synthesis_network.convs.1.noise.noise_strength',\n",
    "'G_synthesis/8x8/Conv1/bias': 'synthesis_network.convs.1.act.bias',\n",
    "'G_synthesis/8x8/ToRGB/weight': 'synthesis_network.trgbs.1.conv.w',\n",
    "'G_synthesis/8x8/ToRGB/mod_weight': 'synthesis_network.trgbs.1.conv.dense.w',\n",
    "'G_synthesis/8x8/ToRGB/mod_bias': 'synthesis_network.trgbs.1.conv.dense.b',\n",
    "'G_synthesis/8x8/ToRGB/bias': 'synthesis_network.trgbs.1.bias',\n",
    "'G_synthesis/16x16/Conv0_up/weight': 'synthesis_network.convs.2.conv.w',\n",
    "'G_synthesis/16x16/Conv0_up/mod_weight': 'synthesis_network.convs.2.conv.dense.w',\n",
    "'G_synthesis/16x16/Conv0_up/mod_bias': 'synthesis_network.convs.2.conv.dense.b',\n",
    "'G_synthesis/16x16/Conv0_up/noise_strength': 'synthesis_network.convs.2.noise.noise_strength',\n",
    "'G_synthesis/16x16/Conv0_up/bias': 'synthesis_network.convs.2.act.bias',\n",
    "'G_synthesis/16x16/Conv1/weight':  'synthesis_network.convs.3.conv.w',\n",
    "'G_synthesis/16x16/Conv1/mod_weight':  'synthesis_network.convs.3.conv.dense.w',\n",
    "'G_synthesis/16x16/Conv1/mod_bias':  'synthesis_network.convs.3.conv.dense.b',\n",
    "'G_synthesis/16x16/Conv1/noise_strength':  'synthesis_network.convs.3.noise.noise_strength',\n",
    "'G_synthesis/16x16/Conv1/bias':  'synthesis_network.convs.3.act.bias',\n",
    "'G_synthesis/16x16/ToRGB/weight': 'synthesis_network.trgbs.2.conv.w',\n",
    "'G_synthesis/16x16/ToRGB/mod_weight': 'synthesis_network.trgbs.2.conv.dense.w',\n",
    "'G_synthesis/16x16/ToRGB/mod_bias': 'synthesis_network.trgbs.2.conv.dense.b',\n",
    "'G_synthesis/16x16/ToRGB/bias': 'synthesis_network.trgbs.2.bias',\n",
    "'G_synthesis/32x32/Conv0_up/weight':  'synthesis_network.convs.4.conv.w',\n",
    "'G_synthesis/32x32/Conv0_up/mod_weight':  'synthesis_network.convs.4.conv.dense.w',\n",
    "'G_synthesis/32x32/Conv0_up/mod_bias':  'synthesis_network.convs.4.conv.dense.b',\n",
    "'G_synthesis/32x32/Conv0_up/noise_strength':  'synthesis_network.convs.4.noise.noise_strength',\n",
    "'G_synthesis/32x32/Conv0_up/bias':  'synthesis_network.convs.4.act.bias',\n",
    "'G_synthesis/32x32/Conv1/weight':  'synthesis_network.convs.5.conv.w',\n",
    "'G_synthesis/32x32/Conv1/mod_weight':  'synthesis_network.convs.5.conv.dense.w',\n",
    "'G_synthesis/32x32/Conv1/mod_bias':  'synthesis_network.convs.5.conv.dense.b',\n",
    "'G_synthesis/32x32/Conv1/noise_strength':  'synthesis_network.convs.5.noise.noise_strength',\n",
    "'G_synthesis/32x32/Conv1/bias':  'synthesis_network.convs.5.act.bias',\n",
    "'G_synthesis/32x32/ToRGB/weight': 'synthesis_network.trgbs.3.conv.w',\n",
    "'G_synthesis/32x32/ToRGB/mod_weight': 'synthesis_network.trgbs.3.conv.dense.w',\n",
    "'G_synthesis/32x32/ToRGB/mod_bias': 'synthesis_network.trgbs.3.conv.dense.b',\n",
    "'G_synthesis/32x32/ToRGB/bias': 'synthesis_network.trgbs.3.bias',\n",
    "'G_synthesis/64x64/Conv0_up/weight':  'synthesis_network.convs.6.conv.w',\n",
    "'G_synthesis/64x64/Conv0_up/mod_weight':  'synthesis_network.convs.6.conv.dense.w',\n",
    "'G_synthesis/64x64/Conv0_up/mod_bias':  'synthesis_network.convs.6.conv.dense.b',\n",
    "'G_synthesis/64x64/Conv0_up/noise_strength':  'synthesis_network.convs.6.noise.noise_strength',\n",
    "'G_synthesis/64x64/Conv0_up/bias':  'synthesis_network.convs.6.act.bias',\n",
    "'G_synthesis/64x64/Conv1/weight':  'synthesis_network.convs.7.conv.w',\n",
    "'G_synthesis/64x64/Conv1/mod_weight':  'synthesis_network.convs.7.conv.dense.w',\n",
    "'G_synthesis/64x64/Conv1/mod_bias':  'synthesis_network.convs.7.conv.dense.b',\n",
    "'G_synthesis/64x64/Conv1/noise_strength':  'synthesis_network.convs.7.noise.noise_strength',\n",
    "'G_synthesis/64x64/Conv1/bias':  'synthesis_network.convs.7.act.bias',\n",
    "'G_synthesis/64x64/ToRGB/weight': 'synthesis_network.trgbs.4.conv.w',\n",
    "'G_synthesis/64x64/ToRGB/mod_weight': 'synthesis_network.trgbs.4.conv.dense.w',\n",
    "'G_synthesis/64x64/ToRGB/mod_bias': 'synthesis_network.trgbs.4.conv.dense.b',\n",
    "'G_synthesis/64x64/ToRGB/bias': 'synthesis_network.trgbs.4.bias',\n",
    "'G_synthesis/128x128/Conv0_up/weight':  'synthesis_network.convs.8.conv.w',\n",
    "'G_synthesis/128x128/Conv0_up/mod_weight':  'synthesis_network.convs.8.conv.dense.w',\n",
    "'G_synthesis/128x128/Conv0_up/mod_bias':  'synthesis_network.convs.8.conv.dense.b',\n",
    "'G_synthesis/128x128/Conv0_up/noise_strength':  'synthesis_network.convs.8.noise.noise_strength',\n",
    "'G_synthesis/128x128/Conv0_up/bias':  'synthesis_network.convs.8.act.bias',\n",
    "'G_synthesis/128x128/Conv1/weight':  'synthesis_network.convs.9.conv.w',\n",
    "'G_synthesis/128x128/Conv1/mod_weight':  'synthesis_network.convs.9.conv.dense.w',\n",
    "'G_synthesis/128x128/Conv1/mod_bias':  'synthesis_network.convs.9.conv.dense.b',\n",
    "'G_synthesis/128x128/Conv1/noise_strength':  'synthesis_network.convs.9.noise.noise_strength',\n",
    "'G_synthesis/128x128/Conv1/bias':  'synthesis_network.convs.9.act.bias',\n",
    "'G_synthesis/128x128/ToRGB/weight': 'synthesis_network.trgbs.5.conv.w',\n",
    "'G_synthesis/128x128/ToRGB/mod_weight': 'synthesis_network.trgbs.5.conv.dense.w',\n",
    "'G_synthesis/128x128/ToRGB/mod_bias': 'synthesis_network.trgbs.5.conv.dense.b',\n",
    "'G_synthesis/128x128/ToRGB/bias': 'synthesis_network.trgbs.5.bias',\n",
    "'G_synthesis/256x256/Conv0_up/weight':  'synthesis_network.convs.10.conv.w',\n",
    "'G_synthesis/256x256/Conv0_up/mod_weight':  'synthesis_network.convs.10.conv.dense.w',\n",
    "'G_synthesis/256x256/Conv0_up/mod_bias':  'synthesis_network.convs.10.conv.dense.b',\n",
    "'G_synthesis/256x256/Conv0_up/noise_strength':  'synthesis_network.convs.10.noise.noise_strength',\n",
    "'G_synthesis/256x256/Conv0_up/bias':  'synthesis_network.convs.10.act.bias',\n",
    "'G_synthesis/256x256/Conv1/weight':  'synthesis_network.convs.11.conv.w',\n",
    "'G_synthesis/256x256/Conv1/mod_weight':  'synthesis_network.convs.11.conv.dense.w',\n",
    "'G_synthesis/256x256/Conv1/mod_bias':  'synthesis_network.convs.11.conv.dense.b',\n",
    "'G_synthesis/256x256/Conv1/noise_strength':  'synthesis_network.convs.11.noise.noise_strength',\n",
    "'G_synthesis/256x256/Conv1/bias':  'synthesis_network.convs.11.act.bias',\n",
    "'G_synthesis/256x256/ToRGB/weight': 'synthesis_network.trgbs.6.conv.w',\n",
    "'G_synthesis/256x256/ToRGB/mod_weight': 'synthesis_network.trgbs.6.conv.dense.w',\n",
    "'G_synthesis/256x256/ToRGB/mod_bias': 'synthesis_network.trgbs.6.conv.dense.b',\n",
    "'G_synthesis/256x256/ToRGB/bias': 'synthesis_network.trgbs.6.bias',\n",
    "'G_mapping/Dense0/weight': 'mapping_network.fc.0.w',\n",
    "'G_mapping/Dense0/bias': 'mapping_network.fc.0.b',\n",
    "'G_mapping/Dense1/weight': 'mapping_network.fc.1.w',\n",
    "'G_mapping/Dense1/bias': 'mapping_network.fc.1.b',\n",
    "'G_mapping/Dense2/weight': 'mapping_network.fc.2.w',\n",
    "'G_mapping/Dense2/bias': 'mapping_network.fc.2.b',\n",
    "'G_mapping/Dense3/weight': 'mapping_network.fc.3.w',\n",
    "'G_mapping/Dense3/bias': 'mapping_network.fc.3.b',\n",
    "'G_mapping/Dense4/weight': 'mapping_network.fc.4.w',\n",
    "'G_mapping/Dense4/bias': 'mapping_network.fc.4.b',\n",
    "'G_mapping/Dense5/weight': 'mapping_network.fc.5.w',\n",
    "'G_mapping/Dense5/bias': 'mapping_network.fc.5.b',\n",
    "'G_mapping/Dense6/weight': 'mapping_network.fc.6.w',\n",
    "'G_mapping/Dense6/bias': 'mapping_network.fc.6.b',\n",
    "'G_mapping/Dense7/weight': 'mapping_network.fc.7.w',\n",
    "'G_mapping/Dense7/bias': 'mapping_network.fc.7.b',\n",
    "}\n",
    "\n",
    "nv2my_D = {\n",
    "'256x256/FromRGB/weight': 'frgb.conv.w',\n",
    "'256x256/FromRGB/bias': 'frgb.conv.bias_act.bias',\n",
    "'256x256/Conv0/weight': 'blocks.0.conv.conv.w',\n",
    "'256x256/Conv0/bias': 'blocks.0.conv.act.bias',\n",
    "'256x256/Conv1_down/weight': 'blocks.0.conv_down.conv.w',\n",
    "'256x256/Conv1_down/bias': 'blocks.0.conv_down.act.bias',\n",
    "'256x256/Skip/weight': 'blocks.0.skip.w',\n",
    "'128x128/Conv0/weight': 'blocks.1.conv.conv.w',\n",
    "'128x128/Conv0/bias': 'blocks.1.conv.act.bias',\n",
    "'128x128/Conv1_down/weight': 'blocks.1.conv_down.conv.w',\n",
    "'128x128/Conv1_down/bias': 'blocks.1.conv_down.act.bias',\n",
    "'128x128/Skip/weight': 'blocks.1.skip.w',\n",
    "'64x64/Conv0/weight': 'blocks.2.conv.conv.w',\n",
    "'64x64/Conv0/bias': 'blocks.2.conv.act.bias',\n",
    "'64x64/Conv1_down/weight': 'blocks.2.conv_down.conv.w',\n",
    "'64x64/Conv1_down/bias': 'blocks.2.conv_down.act.bias',\n",
    "'64x64/Skip/weight': 'blocks.2.skip.w',\n",
    "'32x32/Conv0/weight': 'blocks.3.conv.conv.w',\n",
    "'32x32/Conv0/bias': 'blocks.3.conv.act.bias',\n",
    "'32x32/Conv1_down/weight': 'blocks.3.conv_down.conv.w',\n",
    "'32x32/Conv1_down/bias': 'blocks.3.conv_down.act.bias',\n",
    "'32x32/Skip/weight': 'blocks.3.skip.w',\n",
    "'16x16/Conv0/weight': 'blocks.4.conv.conv.w',\n",
    "'16x16/Conv0/bias': 'blocks.4.conv.act.bias',\n",
    "'16x16/Conv1_down/weight': 'blocks.4.conv_down.conv.w',\n",
    "'16x16/Conv1_down/bias': 'blocks.4.conv_down.act.bias',\n",
    "'16x16/Skip/weight': 'blocks.4.skip.w',\n",
    "'8x8/Conv0/weight': 'blocks.5.conv.conv.w',\n",
    "'8x8/Conv0/bias': 'blocks.5.conv.act.bias',\n",
    "'8x8/Conv1_down/weight': 'blocks.5.conv_down.conv.w',\n",
    "'8x8/Conv1_down/bias': 'blocks.5.conv_down.act.bias',\n",
    "'8x8/Skip/weight': 'blocks.5.skip.w',\n",
    "'4x4/Conv/weight': 'conv_out.conv.w',\n",
    "'4x4/Conv/bias': 'conv_out.act.bias',\n",
    "'4x4/Dense0/weight': 'dense_out.w',\n",
    "'4x4/Dense0/bias': 'dense_out.b',\n",
    "'Output/weight': 'label_out.w',\n",
    "'Output/bias': 'label_out.b',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1707478  -0.7195104  -1.3956457 ]\n",
      " [ 0.06838886 -1.8313364  -0.7966788 ]\n",
      " [-0.09094424  2.052429   -0.97879094]]\n",
      "tensor([[-0.5721, -1.5658, -0.3818],\n",
      "        [ 0.4398, -0.5008, -0.7041],\n",
      "        [ 0.4292, -0.5375,  0.8025]])\n"
     ]
    }
   ],
   "source": [
    "test_target = 'G_synthesis/128x128/Conv0_up/weight'\n",
    "nv_w = np.transpose(w['G'][test_target], (3,2,0,1))\n",
    "print(nv_w[23,17,...])\n",
    "print(g.state_dict()[nv2my_G[test_target]][23,17,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1707, -0.7195, -1.3956],\n",
      "        [ 0.0684, -1.8313, -0.7967],\n",
      "        [-0.0909,  2.0524, -0.9788]])\n"
     ]
    }
   ],
   "source": [
    "g_dict = {k: v for k,v in g.named_parameters()}\n",
    "for nv, my in nv2my_G.items():\n",
    "    if my == '':\n",
    "        continue\n",
    "    \n",
    "    nv_w = w['G'][nv]\n",
    "    if 'conv.w' in my:\n",
    "        nv_w = np.transpose(nv_w, (3,2,0,1))\n",
    "    if 'conv.dense.w' in my:\n",
    "        nv_w = np.transpose(nv_w)\n",
    "    if 'noise_strength' in my:\n",
    "        nv_w = nv_w[..., None]\n",
    "    if 'trgbs' in my and 'bias' in my:\n",
    "        nv_w = np.expand_dims(nv_w, [0,2,3])\n",
    "        \n",
    "#     if nv_w.shape != g.state_dict()[my].shape:\n",
    "#         print(f\"{my}: {nv_w.shape} v.s. {g.state_dict()[my].shape}\")\n",
    "    with torch.no_grad():\n",
    "        g_dict[my].copy_(torch.from_numpy(nv_w))\n",
    "\n",
    "print(g.state_dict()[nv2my_G[test_target]][23,17,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.58197594 -1.254971   -0.57565767]\n",
      " [ 0.90293896  0.14093013  1.165174  ]\n",
      " [ 0.5555504   0.31490085  0.502549  ]]\n",
      "tensor([[-1.2059, -0.4651, -1.5232],\n",
      "        [-1.5982,  0.2501, -0.9110],\n",
      "        [-1.4545,  0.9841,  0.6688]])\n"
     ]
    }
   ],
   "source": [
    "test_target = '64x64/Conv1_down/weight'\n",
    "nv_w = np.transpose(w['D'][test_target], (3,2,0,1))\n",
    "print(nv_w[23,17,...])\n",
    "print(d.state_dict()[nv2my_D[test_target]][23,17,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5820, -1.2550, -0.5757],\n",
      "        [ 0.9029,  0.1409,  1.1652],\n",
      "        [ 0.5556,  0.3149,  0.5025]])\n"
     ]
    }
   ],
   "source": [
    "d_dict = {k: v for k,v in d.named_parameters()}\n",
    "for nv, my in nv2my_D.items():\n",
    "    nv_w = w['D'][nv]\n",
    "    if 'conv.w' in my or 'skip.w' in my:\n",
    "        nv_w = np.transpose(nv_w, (3,2,0,1))\n",
    "    if my in ['dense_out.w', 'label_out.w']:\n",
    "        nv_w = np.transpose(nv_w)\n",
    "    \n",
    "    #if nv_w.shape != d_dict[my].shape:\n",
    "    #    print(f\"{my}: {nv_w.shape} v.s. {d_dict[my].shape}\")\n",
    "    with torch.no_grad():\n",
    "        d_dict[my].copy_(torch.from_numpy(nv_w))\n",
    "        \n",
    "print(d.state_dict()[nv2my_D[test_target]][23,17,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.140891   -0.6883352  -1.363392  ]\n",
      " [ 0.09736779 -1.8005935  -0.7646821 ]\n",
      " [-0.06302303  2.0821478  -0.9466386 ]]\n",
      "tensor([[ 0.1291, -0.4908, -0.0868],\n",
      "        [-0.4467, -0.1995,  0.5081],\n",
      "        [ 1.6732,  1.5413,  0.6888]])\n"
     ]
    }
   ],
   "source": [
    "test_target = 'G_synthesis/128x128/Conv0_up/weight'\n",
    "nv_w = np.transpose(w['G_ema'][test_target], (3,2,0,1))\n",
    "print(nv_w[23,17,...])\n",
    "print(g_ema.state_dict()[nv2my_G[test_target]][23,17,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1409, -0.6883, -1.3634],\n",
      "        [ 0.0974, -1.8006, -0.7647],\n",
      "        [-0.0630,  2.0821, -0.9466]])\n"
     ]
    }
   ],
   "source": [
    "g_ema_dict = {k: v for k,v in g_ema.named_parameters()}\n",
    "for nv, my in nv2my_G.items():\n",
    "    if my == '':\n",
    "        continue\n",
    "    \n",
    "    nv_w = w['G_ema'][nv]\n",
    "    if 'conv.w' in my:\n",
    "        nv_w = np.transpose(nv_w, (3,2,0,1))\n",
    "    if 'conv.dense.w' in my:\n",
    "        nv_w = np.transpose(nv_w)\n",
    "    if 'noise_strength' in my:\n",
    "        nv_w = nv_w[..., None]\n",
    "    if 'trgbs' in my and 'bias' in my:\n",
    "        nv_w = np.expand_dims(nv_w, [0,2,3])\n",
    "        \n",
    "    #if nv_w.shape != g_ema_dict[my].shape:\n",
    "    #    print(f\"{my}: {nv_w.shape} v.s. {g_ema_dict[my].shape}\")\n",
    "    with torch.no_grad():\n",
    "        g_ema_dict[my].copy_(torch.from_numpy(nv_w))\n",
    "        \n",
    "print(g_ema.state_dict()[nv2my_G[test_target]][23,17,...])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## these tensor not been assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthesis_network.trgbs.6.upsample.kernel\n",
    "# synthesis_network.convs.0.conv.blur.kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0625, 0.1875, 0.1875, 0.0625],\n",
       "        [0.1875, 0.5625, 0.5625, 0.1875],\n",
       "        [0.1875, 0.5625, 0.5625, 0.1875],\n",
       "        [0.0625, 0.1875, 0.1875, 0.0625]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.state_dict()['synthesis_network.trgbs.0.upsample.kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0625, 0.1875, 0.1875, 0.0625],\n",
       "        [0.1875, 0.5625, 0.5625, 0.1875],\n",
       "        [0.1875, 0.5625, 0.5625, 0.1875],\n",
       "        [0.0625, 0.1875, 0.1875, 0.0625]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.state_dict()['synthesis_network.convs.0.conv.blur.kernel']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stylegan2",
   "language": "python",
   "name": "stylegan2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
